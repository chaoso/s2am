{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total Dataset of val5k is :  2420\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, absolute_import\n",
    "\n",
    "import os \n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import scripts.utils\n",
    "from scripts.utils.logger import Logger, savefig\n",
    "from scripts.utils.evaluation import accuracy, AverageMeter, final_preds\n",
    "from scripts.utils.misc import save_checkpoint, save_pred, adjust_learning_rate\n",
    "from scripts.utils.osutils import mkdir_p, isfile, isdir, join\n",
    "from scripts.utils.imutils import batch_with_heatmap,normalize_batch,im_to_numpy\n",
    "from scripts.utils.transforms import fliplr, flip_back\n",
    "import scripts.models as models\n",
    "import scripts.datasets as datasets\n",
    "\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "from skimage.measure import compare_psnr as psnr\n",
    "\n",
    "class objectview(object):\n",
    "    \"\"\"Convert dict(or parameters of dict) to object view\n",
    "    See also:\n",
    "        - https://goodcode.io/articles/python-dict-object/\n",
    "        - https://stackoverflow.com/questions/1305532/convert-python-dict-to-object\n",
    "    >>> o = objectview({'a': 1, 'b': 2})\n",
    "    >>> o.a, o.b\n",
    "    (1, 2)\n",
    "    >>> o = objectview(a=1, b=2)\n",
    "    >>> o.a, o.b\n",
    "    (1, 2)\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        d = dict(*args, **kwargs)\n",
    "        self.__dict__ = d\n",
    "\n",
    "\n",
    "dataset_name= 'val5k'\n",
    "dataroot = '/home/oishii/Datasets/backup/fivek'\n",
    "input_size = 256\n",
    "\n",
    "data_config_normal  = objectview({'input_size':input_size,\n",
    "                           'limited_dataset':0,\n",
    "                           'resize_and_crop':'resize',\n",
    "                           'data_augumentation':False,\n",
    "                           'norm_type':'none',\n",
    "                           'base_dir':dataroot,\n",
    "                           'data':dataset_name})\n",
    "\n",
    "data_config_gan  = objectview({'input_size':input_size,\n",
    "                           'limited_dataset':0,\n",
    "                           'resize_and_crop':'resize',\n",
    "                           'norm_type':'gan',\n",
    "                           'base_dir':dataroot,\n",
    "                           'data':dataset_name})\n",
    "\n",
    "\n",
    "methods = [\n",
    "           ('/home/oishii/Documents/imageharmonization/rasc_temp/psnr/adobe5k/1e3_bs16_256_basic_5k_rascv1',data_config_normal),\n",
    "        ('/home/oishii/Documents/imageharmonization/rasc_temp/psnr/adobe5k/1e3_bs16_256_basic_5k_rascv2',data_config_normal),\n",
    "#             ('/home/oishii/Documents/imageharmonization/rasc-v2/limited/cocov4/1e3_bs16_256_multimaskedpixel_2017_naivemmucross',data_config_normal),\n",
    "#             ('/home/oishii/Documents/imageharmonization/rasc-v2/limited/cocov4gan/1e3_bs16_256_mmaskedgan_2017_naivemmucross',data_config_gan),\n",
    "#     ('/home/oishii/Documents/imageharmonization/rasc-v2/limited/cocov4gan/1e3_bs16_256_baseline_mmaskedgan_2017_naivemmucross',data_config_gan),\n",
    "#     ('/home/oishii/Documents/imageharmonization/rasc-v2/limited/cocov4gan/1e3_bs16_256_gagan_2017_globalattentionnetwork',data_config_gan),\n",
    "#     ('/home/oishii/Documents/imageharmonization/rasc-v2/limited/cocov4gan/1e3_bs16_256_mmaskedgan_2017_naivemmucrossx',data_config_gan)\n",
    "]\n",
    "\n",
    "sample = []\n",
    "\n",
    "for resume,data_config in methods:\n",
    "  \n",
    "    #os.makedirs(os.path.join(resume,dataset_name,'output'),exist_ok=True)\n",
    "    \n",
    "            \n",
    "    val_loader = torch.utils.data.DataLoader(datasets.COCO('',args=data_config),\n",
    "                                         batch_size=1, shuffle=False,\n",
    "                                         num_workers=2, pin_memory=False)\n",
    "    epoches = '/checkpoint.pth.tar'\n",
    "    checkpoint_dict = torch.load(resume+epoches)\n",
    "    checkpoint = checkpoint_dict['state_dict']\n",
    "        \n",
    "\n",
    "    name_of_model = resume.split('_')[-1]\n",
    "    \n",
    "\n",
    "    model = models.__dict__[name_of_model]().cuda()\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "    \n",
    "    MSE = AverageMeter()\n",
    "    PSNR = AverageMeter()\n",
    "    SSIM = AverageMeter()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, target) in enumerate(val_loader):            \n",
    "            inputs = inputs.cuda()\n",
    "            target = target.cuda()\n",
    "            mask = inputs[0,3:4]\n",
    "           \n",
    "            if 'rasc' in resume:\n",
    "                output = model(inputs)\n",
    "                mask2s = inputs[0,3:4]\n",
    "            elif 'gagan' in resume:\n",
    "                output,mask2s = model(inputs)\n",
    "            else:\n",
    "                output,mask8s,mask4s,mask2s = model(inputs)\n",
    "                mask2s = nn.functional.interpolate(mask2s,scale_factor=2)\n",
    "            \n",
    "             # if gan based method\n",
    "            if 'gan' in data_config.norm_type:\n",
    "                outputnp = (im_to_numpy(output[0]) + 1) / 2.0 * 255.0\n",
    "                inputsnp = (im_to_numpy(inputs[0,0:3]) + 1) / 2.0 * 255.0\n",
    "                targetnp = (im_to_numpy(target[0]) + 1) / 2.0 * 255.0\n",
    "                outputnp = outputnp.clip(0,255).astype(np.uint8)\n",
    "                inputsnp = inputsnp.clip(0,255).astype(np.uint8)\n",
    "                targetnp = targetnp.clip(0,255).astype(np.uint8)\n",
    "            else:\n",
    "                inputsnp = (im_to_numpy(inputs[0,0:3])*255).clip(0,255).astype(np.uint8)\n",
    "                outputnp = (im_to_numpy(output[0])*255).clip(0,255).astype(np.uint8)\n",
    "                targetnp = (im_to_numpy(target[0])*255).clip(0,255).astype(np.uint8)\n",
    "                \n",
    "            masknp = im_to_numpy(mask.repeat(3,1,1)).astype(np.uint8)\n",
    "            \n",
    "            tmp_ssim = ssim(targetnp,outputnp,multichannel=True)\n",
    "            tmp_psnr = psnr(targetnp,outputnp)\n",
    "            tmp_mse = np.mean( (outputnp - targetnp) ** 2 )\n",
    "            \n",
    "            MSE.update(tmp_mse, inputs.size(0))\n",
    "            PSNR.update(tmp_psnr, inputs.size(0))\n",
    "            SSIM.update(tmp_ssim, inputs.size(0))\n",
    "            \n",
    "#             torchvision.utils.save_image(output[0],os.path.join(resume,dataset_name,'output','%s.png'%(i)),padding=0)\n",
    "            \n",
    "    print(\"%s: MSE:%s, SSIM:%s, PSNR:%s\"%(resume.split('/')[-1], MSE.avg, SSIM.avg, PSNR.avg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total Dataset of val2017 is :  1716\n",
      "/home/oishii/Documents/deep-harimonization-improved/psnr/cocov4/1e3_bs8_256_2017_unet: MSE:17.28237579215285, SSIM:0.9757684633437844, PSNR:33.55681231416759\n",
      "total Dataset of val2017 is :  1716\n",
      "/home/oishii/Documents/deep-harimonization-improved/psnr/cocov4/1e3_bs8_256_2017_unetconv: MSE:17.85627645805258, SSIM:0.9757584460044089, PSNR:33.349426540741185\n",
      "total Dataset of val2017 is :  1716\n",
      "/home/oishii/Documents/deep-harimonization-improved/psnr/cocov4/1e3_bs8_256_2017_radhnv3xgaussian: MSE:15.599634133481945, SSIM:0.979036533803898, PSNR:34.74366374129477\n",
      "total Dataset of val2017 is :  1716\n",
      "/home/oishii/Documents/deep-harimonization-improved/psnr/cocov4/1e3_bs8_256_2017_radhnv1: MSE:17.935396112947377, SSIM:0.9758088011985688, PSNR:33.324841910413326\n",
      "total Dataset of val2017 is :  1716\n",
      "/home/oishii/Documents/deep-harimonization-improved/psnr/cocov4/1e3_bs8_256_2017_radhnv2: MSE:15.80662498385201, SSIM:0.9779920592634598, PSNR:34.494394724813844\n",
      "total Dataset of val2017 is :  1716\n",
      "/home/oishii/Documents/deep-harimonization-improved/psnr/cocov4/1e3_bs8_256_2017_radhnv3: MSE:15.676165725245626, SSIM:0.9788325833919882, PSNR:34.72468454237379\n",
      "total Dataset of val2017 is :  1716\n",
      "/home/oishii/Documents/deep-harimonization-improved/psnr/cocov4/1e3_bs8_256_2017_radhnv3x6: MSE:15.665737187667888, SSIM:0.9787735299387941, PSNR:34.73077430311494\n"
     ]
    }
   ],
   "source": [
    "# ablation study\n",
    "\n",
    "from __future__ import print_function, absolute_import\n",
    "\n",
    "import os \n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import scripts.utils\n",
    "from scripts.utils.logger import Logger, savefig\n",
    "from scripts.utils.evaluation import accuracy, AverageMeter, final_preds\n",
    "from scripts.utils.misc import save_checkpoint, save_pred, adjust_learning_rate\n",
    "from scripts.utils.osutils import mkdir_p, isfile, isdir, join\n",
    "from scripts.utils.imutils import batch_with_heatmap,normalize_batch,im_to_numpy\n",
    "from scripts.utils.transforms import fliplr, flip_back\n",
    "import scripts.models as models\n",
    "import scripts.datasets as datasets\n",
    "\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "from skimage.measure import compare_psnr as psnr\n",
    "\n",
    "class objectview(object):\n",
    "    \"\"\"Convert dict(or parameters of dict) to object view\n",
    "    See also:\n",
    "        - https://goodcode.io/articles/python-dict-object/\n",
    "        - https://stackoverflow.com/questions/1305532/convert-python-dict-to-object\n",
    "    >>> o = objectview({'a': 1, 'b': 2})\n",
    "    >>> o.a, o.b\n",
    "    (1, 2)\n",
    "    >>> o = objectview(a=1, b=2)\n",
    "    >>> o.a, o.b\n",
    "    (1, 2)\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        d = dict(*args, **kwargs)\n",
    "        self.__dict__ = d\n",
    "            \n",
    "# COCO-val2017\n",
    "methods = (\n",
    "           '/home/oishii/Documents/deep-harimonization-improved/psnr/cocov4/1e3_bs8_256_2017_unet',\n",
    "           '/home/oishii/Documents/deep-harimonization-improved/psnr/cocov4/1e3_bs8_256_2017_unetconv',\n",
    "           '/home/oishii/Documents/deep-harimonization-improved/psnr/cocov4/1e3_bs8_256_2017_radhnv3xgaussian',\n",
    "            '/home/oishii/Documents/deep-harimonization-improved/psnr/cocov4/1e3_bs8_256_2017_radhnv1',\n",
    "    '/home/oishii/Documents/deep-harimonization-improved/psnr/cocov4/1e3_bs8_256_2017_radhnv2',\n",
    "    '/home/oishii/Documents/deep-harimonization-improved/psnr/cocov4/1e3_bs8_256_2017_radhnv3',\n",
    "    '/home/oishii/Documents/deep-harimonization-improved/psnr/cocov4/1e3_bs8_256_2017_radhnv3x6'\n",
    "         )\n",
    "\n",
    "dataset_name= 'val2017'\n",
    "dataroot = '/home/oishii/Documents/coco_data_maker/synthesis_coco_v4/'\n",
    "\n",
    "sample = []\n",
    "\n",
    "for resume in methods:\n",
    "\n",
    "    if 'pix2pix' in resume:\n",
    "        data_config  = objectview({'input_size':256,'normalized_input':False,'data_augumentation':False,'withseg':False})\n",
    "        val_loader = torch.utils.data.DataLoader(datasets.COCO(dataroot,dataset_name,config=data_config,sample=sample,gan_norm=True),\n",
    "                                             batch_size=1, shuffle=False,\n",
    "                                             num_workers=2, pin_memory=False)\n",
    "        epoches = '/latest_net_G.pth'\n",
    "        checkpoint = torch.load(resume+epoches)\n",
    "    else:\n",
    "        if 'seg' in resume:\n",
    "            data_config  = objectview({'input_size':256,'normalized_input':False,'data_augumentation':False,'withseg':True})\n",
    "        else:\n",
    "            data_config  = objectview({'input_size':256,'normalized_input':False,'data_augumentation':False,'withseg':False})\n",
    "            \n",
    "        val_loader = torch.utils.data.DataLoader(datasets.COCO(dataroot,dataset_name,config=data_config,sample=sample,gan_norm=False),\n",
    "                                             batch_size=1, shuffle=False,\n",
    "                                             num_workers=2, pin_memory=False)\n",
    "        epoches = '/model_best.pth.tar'\n",
    "        checkpoint_dict = torch.load(resume+epoches)\n",
    "        checkpoint = checkpoint_dict['state_dict']\n",
    "    \n",
    "    if 'pix2pix' in resume:\n",
    "        name_of_model = 'ounet'\n",
    "    else:\n",
    "        name_of_model = resume.split('_')[-1]\n",
    "    \n",
    "    model = models.__dict__[name_of_model]().cuda()\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "    \n",
    "    MSE = AverageMeter()\n",
    "    PSNR = AverageMeter()\n",
    "    SSIM = AverageMeter()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, target) in enumerate(val_loader):            \n",
    "            inputs = inputs.cuda()\n",
    "            target = target[0].cuda()\n",
    "            \n",
    "            if 'unet' in resume:\n",
    "                output = model(inputs)\n",
    "            elif 'seg' in resume:\n",
    "                output,_ = model(inputs)\n",
    "            else:\n",
    "                output = model(inputs)\n",
    "                \n",
    "             # if gan based method\n",
    "            if 'pix2pix' in resume:\n",
    "                outputnp = (im_to_numpy(output[0]) + 1) / 2.0 * 255.0\n",
    "                inputsnp = (im_to_numpy(inputs[0,0:3]) + 1) / 2.0 * 255.0\n",
    "                outputnp = outputnp.clip(0,255).astype(np.uint8)\n",
    "                inputsnp = inputsnp.clip(0,255).astype(np.uint8)\n",
    "                targetnp = (im_to_numpy(target[0])*255).astype(np.uint8)\n",
    "            else:\n",
    "                inputsnp = (im_to_numpy(inputs[0,0:3])*255).clip(0,255).astype(np.uint8)\n",
    "                outputnp = (im_to_numpy(output[0])*255).clip(0,255).astype(np.uint8)\n",
    "                targetnp = (im_to_numpy(target[0])*255).astype(np.uint8)\n",
    "            \n",
    "            tmp_ssim = ssim(targetnp,outputnp,multichannel=True)\n",
    "            tmp_psnr = psnr(targetnp,outputnp)\n",
    "            tmp_mse = np.mean( (outputnp - targetnp) ** 2 )\n",
    "            \n",
    "            MSE.update(tmp_mse, inputs.size(0))\n",
    "            PSNR.update(tmp_psnr, inputs.size(0))\n",
    "            SSIM.update(tmp_ssim, inputs.size(0))\n",
    "            \n",
    "#             torchvision.utils.save_image(inputs[0,3:4,:,:],os.path.join(resume,dataset_name,'mask','%s.png'%(i)),padding=0)\n",
    "#             torchvision.utils.save_image(target[0],os.path.join(resume,dataset_name,'target','%s.png'%(i)),padding=0)\n",
    "#             torchvision.utils.save_image(inputs[0,0:3,:,:],os.path.join(resume,dataset_name,'input','%s.png'%(i)),padding=0)\n",
    "#             torchvision.utils.save_image(output[0],os.path.join(resume,dataset_name,'output','%s.png'%(i)),padding=0)\n",
    "            \n",
    "    print(\"%s: MSE:%s, SSIM:%s, PSNR:%s\"%(resume, MSE.avg, SSIM.avg, PSNR.avg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
