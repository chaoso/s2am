{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total Dataset of val5k is :  2420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../scripts/utils/model_init.py:38: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(m.weight.data, 1.0, 0.02)\n",
      "../scripts/utils/model_init.py:39: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(m.bias.data, 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/oishii/Documents/deep-harimonization-improved/psnr/adobe5k/1e3_bs16_256_5k_can: MSE:25.99098691283512, SSIM:0.9062486607292697, PSNR:23.718771400806354\n",
      "/home/oishii/Documents/deep-harimonization-improved/psnr/adobe5k/1e3_bs16_256_5k_dih256: MSE:34.97740772552063, SSIM:0.862660646693442, PSNR:20.956739032792978\n",
      "/home/oishii/Documents/deep-harimonization-improved/psnr/adobe5k/1e3_bs16_256_5k_dihrasc: MSE:27.153652462289365, SSIM:0.9259332316411045, PSNR:24.730374635275105\n",
      "/home/oishii/Documents/deep-harimonization-improved/psnr/adobe5k/1e3_bs16_256_5k_radhnv3xgaussian: MSE:21.875379460442467, SSIM:0.9571092344930275, PSNR:28.909926169442468\n",
      "/home/oishii/Documents/deep-harimonization-improved/psnr/adobe5k/1e3_bs16_256_5k_unet: MSE:23.212920585611336, SSIM:0.9491754482234419, PSNR:27.07506575555279\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, absolute_import\n",
    "\n",
    "import os \n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "import scripts.utils\n",
    "from scripts.utils.logger import Logger, savefig\n",
    "from scripts.utils.evaluation import accuracy, AverageMeter, final_preds\n",
    "from scripts.utils.misc import save_checkpoint, save_pred, adjust_learning_rate\n",
    "from scripts.utils.osutils import mkdir_p, isfile, isdir, join\n",
    "from scripts.utils.imutils import batch_with_heatmap,normalize_batch,im_to_numpy\n",
    "from scripts.utils.transforms import fliplr, flip_back\n",
    "import scripts.models as models\n",
    "import scripts.datasets as datasets\n",
    "\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "from skimage.measure import compare_psnr as psnr\n",
    "\n",
    "class objectview(object):\n",
    "    \"\"\"Convert dict(or parameters of dict) to object view\n",
    "    See also:\n",
    "        - https://goodcode.io/articles/python-dict-object/\n",
    "        - https://stackoverflow.com/questions/1305532/convert-python-dict-to-object\n",
    "    >>> o = objectview({'a': 1, 'b': 2})\n",
    "    >>> o.a, o.b\n",
    "    (1, 2)\n",
    "    >>> o = objectview(a=1, b=2)\n",
    "    >>> o.a, o.b\n",
    "    (1, 2)\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        d = dict(*args, **kwargs)\n",
    "        self.__dict__ = d\n",
    "\n",
    "        \n",
    "methods = ('/home/oishii/Documents/deep-harimonization-improved/psnr/adobe5k/1e3_bs16_256_5k_can',\n",
    "          '/home/oishii/Documents/deep-harimonization-improved/psnr/adobe5k/1e3_bs16_256_5k_dih256',\n",
    "          '/home/oishii/Documents/deep-harimonization-improved/psnr/adobe5k/1e3_bs16_256_5k_dihrasc',\n",
    "          '/home/oishii/Documents/deep-harimonization-improved/psnr/adobe5k/1e3_bs16_256_5k_radhnv3xgaussian',\n",
    "          '/home/oishii/Documents/deep-harimonization-improved/psnr/adobe5k/1e3_bs16_256_5k_unet'\n",
    "          )\n",
    "\n",
    "dataset_name= 'val5k'\n",
    "dataroot = '/home/oishii/Datasets/fivek/'\n",
    "\n",
    "data_config  = objectview({'input_size':256,'normalized_input':False,'data_augumentation':False,'withseg':False})\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        datasets.COCO(dataroot,dataset_name,config=data_config),\n",
    "        batch_size=1, shuffle=False,\n",
    "        num_workers=2, pin_memory=False)\n",
    "\n",
    "for resume in methods:\n",
    "\n",
    "    os.makedirs(os.path.join(resume,dataset_name,'input'),exist_ok=True)\n",
    "    os.makedirs(os.path.join(resume,dataset_name,'output'),exist_ok=True)\n",
    "    os.makedirs(os.path.join(resume,dataset_name,'mask'),exist_ok=True)\n",
    "    os.makedirs(os.path.join(resume,dataset_name,'target'),exist_ok=True)\n",
    "#     os.makedirs(os.path.join(resume,dataset_name,'all'),exist_ok=True)\n",
    "#     if 'styleloss' in resume:\n",
    "#         model = models.__dict__[resume.replace('xstyleloss','').split('_')[-1]]().cuda()\n",
    "#     else:\n",
    "    model = models.__dict__[resume.split('_')[-1]]().cuda()\n",
    "    checkpoint = torch.load(resume+'/model_best.pth.tar')\n",
    "    best_scc = checkpoint['best_acc']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    MSE = AverageMeter()\n",
    "    PSNR = AverageMeter()\n",
    "    SSIM = AverageMeter()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, target) in enumerate(val_loader):            \n",
    "            inputs = inputs.cuda()\n",
    "            target = target[0].cuda()\n",
    "            output = model(inputs)\n",
    " \n",
    "            outputnp = (im_to_numpy(output[0])*255).astype(np.uint8)\n",
    "            targetnp = (im_to_numpy(target[0])*255).astype(np.uint8)\n",
    "            inputsnp = (im_to_numpy(inputs[0,0:3])*255).astype(np.uint8)\n",
    "            \n",
    "            tmp_ssim = ssim(targetnp,outputnp,multichannel=True)\n",
    "            tmp_psnr = psnr(targetnp,outputnp)\n",
    "            tmp_mse = np.mean( (outputnp - targetnp) ** 2 )\n",
    "            \n",
    "            MSE.update(tmp_mse, inputs.size(0))\n",
    "            PSNR.update(tmp_psnr, inputs.size(0))\n",
    "            SSIM.update(tmp_ssim, inputs.size(0))\n",
    "            \n",
    "            torchvision.utils.save_image(inputs[0,3:4,:,:],os.path.join(resume,dataset_name,'mask','%s.png'%(i)),padding=0)\n",
    "            torchvision.utils.save_image(target[0],os.path.join(resume,dataset_name,'target','%s.png'%(i)),padding=0)\n",
    "            torchvision.utils.save_image(inputs[0,0:3,:,:],os.path.join(resume,dataset_name,'input','%s.png'%(i)),padding=0)\n",
    "            torchvision.utils.save_image(output[0],os.path.join(resume,dataset_name,'output','%s.png'%(i)),padding=0)\n",
    "#             torchvision.utils.save_image(torch.cat([inputs[:,0:3,:,:],target,output],dim=0),os.path.join(resume,dataset_name,'all','%s.png'%(i)))\n",
    "            \n",
    "    print(\"%s: MSE:%s, SSIM:%s, PSNR:%s\"%(resume, MSE.avg, SSIM.avg, PSNR.avg))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
