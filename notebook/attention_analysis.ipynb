{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total Dataset of val2017 is :  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f96656b6a90>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAA6RJREFUeJzt3D1KHVEAgNE8SSGEgCaFTRoXkM4luIRswC3YZRNZQuzNElyBYCHBwla7FCEGm2jIG7tnBgt/wFH5zqnmcuG+aT7uHZh5s2EYXgEtS099A8D0hA9Bwocg4UOQ8CFI+BAkfAgSPgQJH4JeT/ljG1tfvCYId7R89m80/vvmep9e+X42mpsfHS+u9+bfZretbceHIOFD0KRHfeDufq+P87x4d/2kvHo4H82d7H6819p2fAgSPgQJH4I848MztXQ5Hq/v/lpc/9x4P5q7/HNxv7UffFfAiyV8CHLUh2dq7dPJaHz+48Pi+u3p+Gi/v/n1v9HnW9e240OQ8CFI+BA0m/J/9X2dB4/vYGfb13nATcKHIOFDkPAhSPgQJHwIEj4ECR+ChA9Bwocg4UOQ8CFI+BAkfAgSPgQJH4KED0HChyDhQ5DwIUj4ECR8CBI+BAkfgoQPQcKHIOFDkPAhSPgQJHwIEj4ECR+ChA9Bwocg4UOQ8CFI+BAkfAgSPgQJH4KED0HChyDhQ5DwIUj4ECR8CBI+BAkfgoQPQcKHIOFDkPAhSPgQJHwIEj4ECR+ChA9Bwocg4UOQ8CFI+BAkfAgSPgQJH4KED0HChyDhQ5DwIUj4ECR8CBI+BAkfgoQPQcKHIOFDkPAhSPgQJHwIEj4ECR+ChA9Bwocg4UOQ8CFI+BAkfAgSPgQJH4KED0HChyDhQ5DwIUj4ECR8CBI+BAkfgoQPQcKHIOFDkPAhSPgQJHwIEj4ECR+ChA9Bwocg4UOQ8CFI+BAkfAgSPgQJH4KED0HChyDhQ5DwIUj4ECR8CBI+BAkfgoQPQcKHIOFDkPAhSPgQJHwIEj4ECR+ChA9Bwocg4UOQ8CFI+BAkfAgSPgQJH4KED0HChyDhQ5DwIUj4ECR8CBI+BAkfgoQPQcKHIOFDkPAhSPgQJHwIEj4ECR+ChA9Bwocg4UOQ8CFI+BAkfAgSPgQJH4KED0HChyDhQ5DwIUj4ECR8CBI+BAkfgoQPQcKHIOFDkPAhSPgQJHwIEj4ECR+ChA9Bwocg4UOQ8CFI+BAkfAgSPgQJH4KED0HChyDhQ5DwIUj4ECR8CBI+BAkfgoQPQcKHIOFDkPAhSPgQJHwIEj4ECR+ChA9Bwocg4UPQbBiGp74HYGJ2fAgSPgQJH4KED0HChyDhQ5DwIUj4ECR8CBI+BAkfgoQPQcKHIOFDkPAhSPgQJHwIEj4ECR+ChA9Bwocg4UOQ8CHoCgHtL9Gj6Jh2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f95faf7bf98>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function, absolute_import\n",
    "\n",
    "import os \n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageChops\n",
    "import scipy.misc\n",
    "import sys, math\n",
    "sys.path.append('..')\n",
    "\n",
    "import scripts.utils\n",
    "from scripts.utils.logger import Logger, savefig\n",
    "from scripts.utils.evaluation import accuracy, AverageMeter, final_preds\n",
    "from scripts.utils.misc import save_checkpoint, save_pred, adjust_learning_rate\n",
    "from scripts.utils.osutils import mkdir_p, isfile, isdir, join\n",
    "from scripts.utils.imutils import batch_with_heatmap,normalize_batch,im_to_numpy\n",
    "from scripts.utils.transforms import fliplr, flip_back\n",
    "import scripts.models as models\n",
    "import scripts.datasets as datasets\n",
    "import random\n",
    "from matplotlib import cm\n",
    "\n",
    "class objectview(object):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        d = dict(*args, **kwargs)\n",
    "        self.__dict__ = d\n",
    "\n",
    "\n",
    "dataset_name= 'val2017'\n",
    "dataroot = '/home/oishii/Documents/coco_data_maker/synthesis_coco_v4/'\n",
    "\n",
    "data_config  = objectview({'input_size':256,'normalized_input':False,'data_augumentation':False,'withseg':False})\n",
    "sample = random.sample(range(1500), 1);\n",
    "# sample=[557]\n",
    "\n",
    "def hook1(module,inputdata,output):\n",
    "    dd = output.data[0].numpy()\n",
    "    np.savetxt('background.out',np.squeeze(dd))\n",
    "    \n",
    "def hook2(module,inputdata,output):\n",
    "    dd = output.data[0].numpy()\n",
    "    np.savetxt('mixed.out',np.squeeze(dd))\n",
    "    \n",
    "def hook3(module,inputdata,output):\n",
    "    dd = output.data[0].numpy()\n",
    "    np.savetxt('spliced.out',dd)\n",
    "    \n",
    "def hook4(module,inputdata,output):\n",
    "    dd = output.data[0].numpy()\n",
    "    np.savetxt('background2.out',dd)\n",
    "    \n",
    "def hook5(module,inputdata,output):\n",
    "    dd = output.data[0].numpy()\n",
    "    np.savetxt('mixed2.out',dd)\n",
    "    \n",
    "def hook6(module,inputdata,output):\n",
    "    dd = output.data[0].numpy()\n",
    "    np.savetxt('spliced2.out',dd)\n",
    "    \n",
    "def hook7(module,inputdata,output):\n",
    "    dd = output.data[0].numpy()\n",
    "    np.savetxt('background3.out',dd)\n",
    "    \n",
    "def hook8(module,inputdata,output):\n",
    "    dd = output.data[0].numpy()\n",
    "    np.savetxt('mixed3.out',dd)\n",
    "    \n",
    "def hook9(module,inputdata,output):\n",
    "    dd = output.data[0].numpy()\n",
    "    np.savetxt('spliced3.out',dd)\n",
    "    \n",
    "def feature_hook(module,inputdata,output):\n",
    "    dd = output.data[0].numpy()\n",
    "#     for i in range(dd.shape[0]):\n",
    "# #         normalized\n",
    "#         a = dd[i,:,:]\n",
    "#         im = (255*(a - np.min(a))/np.ptp(a)).astype(np.uint8)\n",
    "#         imm = Image.fromarray(im)\n",
    "#         imm.save('%s.png'%str(i))\n",
    "        \n",
    "    \n",
    "    \n",
    "# run with gan-based method            \n",
    "with torch.no_grad():\n",
    "        val_loader = torch.utils.data.DataLoader(datasets.COCO(dataroot,dataset_name,config=data_config,sample=sample,gan_norm=False),\n",
    "                                                 batch_size=1, shuffle=False,\n",
    "                                                 num_workers=1, pin_memory=False)\n",
    "        checkpoint_dict = torch.load('/home/oishii/Documents/deep-harimonization-improved/psnr/cocov4/1e3_bs8_256_2017_radhnv3xnomask/model_best.pth.tar')\n",
    "            \n",
    "        for i, (inputs, target) in enumerate(val_loader):            \n",
    "            \n",
    "            model = models.__dict__['radhnv3xnomask']()\n",
    "            model.load_state_dict(checkpoint_dict['state_dict'])\n",
    "            model.eval()\n",
    "\n",
    "            inputs = inputs\n",
    "            target = target[0]\n",
    "            handle1 = model.model.model.sub.model.attention.mask_attention.fc.register_forward_hook(hook1)\n",
    "            handle2 = model.model.model.sub.model.sub.model.attention.mask_attention.fc.register_forward_hook(hook2)\n",
    "            \n",
    "            output = model(inputs)\n",
    "            \n",
    "            torchvision.utils.save_image(inputs[0,0:3,:,:],\"%s.png\"%sample)\n",
    "            torchvision.utils.save_image(inputs[0,3:4,:,:],\"%s_mask.png\"%sample)\n",
    "            \n",
    "            handle1.remove()\n",
    "            handle2.remove()\n",
    "        \n",
    "            \n",
    "#             print(model.model.model.sub.model.attention.spliced_attention.fc)\n",
    "            \n",
    "\n",
    "# x31 = np.genfromtxt('spliced.out').reshape((1,64)).repeat(8,axis=1).repeat(8,axis=0);\n",
    "\n",
    "# x12 = np.genfromtxt('background2.out').reshape((1,128)).repeat(4,axis=1).repeat(4,axis=0);\n",
    "# x22 = np.genfromtxt('mixed2.out').reshape((1,128)).repeat(4,axis=1).repeat(4,axis=0);\n",
    "# x32 = np.genfromtxt('spliced2.out').reshape((1,128)).repeat(4,axis=1).repeat(4,axis=0);\n",
    "\n",
    "\n",
    "# x13 = np.genfromtxt('background3.out').reshape((1,256)).repeat(2,axis=1).repeat(2,axis=0);\n",
    "# x23 = np.genfromtxt('mixed3.out').reshape((1,256)).repeat(2,axis=1).repeat(2,axis=0);\n",
    "# x33 = np.genfromtxt('spliced3.out').reshape((1,256)).repeat(2,axis=1).repeat(2,axis=0);\n",
    "\n",
    "\n",
    "# img = (np.concatenate((x11,x21,x31,line,x12,x22,x32,line,x13,x23,x33),axis=0).clip(0,1)*255).astype(np.uint8);\n",
    "\n",
    "# plt.imshow(img)\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "# Image.fromarray(img[:,192:256]).save(\"%s_attention.png\"%sample)           \n",
    "        # line = np.zeros((1,512))\n",
    "x11 = np.genfromtxt('background.out');\n",
    "x21 = np.genfromtxt('mixed.out');\n",
    "\n",
    "\n",
    "plt.imshow(x11)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(x21)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnetGenerator(\n",
      "  (model): UnetSkipConnectionBlock(\n",
      "    (model): MinimalUnet(\n",
      "      (down): Sequential(\n",
      "        (0): Conv2d(4, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (up): Sequential(\n",
      "        (0): ReLU(inplace)\n",
      "        (1): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (sub): UnetSkipConnectionBlock(\n",
      "        (model): MinimalUnet(\n",
      "          (down): Sequential(\n",
      "            (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "            (1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (up): Sequential(\n",
      "            (0): ReLU(inplace)\n",
      "            (1): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (sub): UnetSkipConnectionBlock(\n",
      "            (model): MinimalUnet(\n",
      "              (down): Sequential(\n",
      "                (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (up): Sequential(\n",
      "                (0): ReLU(inplace)\n",
      "                (1): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (sub): UnetSkipConnectionBlock(\n",
      "                (model): MinimalUnet(\n",
      "                  (down): Sequential(\n",
      "                    (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                    (1): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                  (up): Sequential(\n",
      "                    (0): ReLU(inplace)\n",
      "                    (1): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                  (sub): UnetSkipConnectionBlock(\n",
      "                    (model): MinimalUnet(\n",
      "                      (down): Sequential(\n",
      "                        (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                        (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                      )\n",
      "                      (up): Sequential(\n",
      "                        (0): ReLU(inplace)\n",
      "                        (1): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                      )\n",
      "                      (sub): UnetSkipConnectionBlock(\n",
      "                        (model): MinimalUnet(\n",
      "                          (down): Sequential(\n",
      "                            (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                            (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                            (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                          )\n",
      "                          (up): Sequential(\n",
      "                            (0): ReLU(inplace)\n",
      "                            (1): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                            (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                          )\n",
      "                          (sub): UnetSkipConnectionBlock(\n",
      "                            (model): MinimalUnet(\n",
      "                              (down): Sequential(\n",
      "                                (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                                (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                              )\n",
      "                              (up): Sequential(\n",
      "                                (0): ReLU(inplace)\n",
      "                                (1): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                              )\n",
      "                              (sub): UnetSkipConnectionBlock(\n",
      "                                (model): MinimalUnet(\n",
      "                                  (down): Sequential(\n",
      "                                    (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                                    (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                  )\n",
      "                                  (up): Sequential(\n",
      "                                    (0): ReLU(inplace)\n",
      "                                    (1): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                                  )\n",
      "                                )\n",
      "                              )\n",
      "                            )\n",
      "                          )\n",
      "                        )\n",
      "                      )\n",
      "                    )\n",
      "                  )\n",
      "                  (attention): RegionalAttentionConnectGaussianMask(\n",
      "                    (connection): RegionalSkipConnect(\n",
      "                      (rconv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                      (rbn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                      (rconv2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                      (rbn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (background_attention): GlobalAttentionModule(\n",
      "                      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "                      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "                      (fc): Sequential(\n",
      "                        (0): Linear(in_features=512, out_features=16, bias=True)\n",
      "                        (1): ReLU(inplace)\n",
      "                        (2): Linear(in_features=16, out_features=256, bias=True)\n",
      "                        (3): Sigmoid()\n",
      "                      )\n",
      "                    )\n",
      "                    (mixed_attention): GlobalAttentionModule(\n",
      "                      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "                      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "                      (fc): Sequential(\n",
      "                        (0): Linear(in_features=512, out_features=16, bias=True)\n",
      "                        (1): ReLU(inplace)\n",
      "                        (2): Linear(in_features=16, out_features=256, bias=True)\n",
      "                        (3): Sigmoid()\n",
      "                      )\n",
      "                    )\n",
      "                    (spliced_attention): GlobalAttentionModule(\n",
      "                      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "                      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "                      (fc): Sequential(\n",
      "                        (0): Linear(in_features=512, out_features=16, bias=True)\n",
      "                        (1): ReLU(inplace)\n",
      "                        (2): Linear(in_features=16, out_features=256, bias=True)\n",
      "                        (3): Sigmoid()\n",
      "                      )\n",
      "                    )\n",
      "                    (gaussianMask): GaussianSmoothing()\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (attention): RegionalAttentionConnectGaussianMask(\n",
      "                (connection): RegionalSkipConnect(\n",
      "                  (rconv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (rbn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (rconv2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (rbn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "                (background_attention): GlobalAttentionModule(\n",
      "                  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "                  (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "                  (fc): Sequential(\n",
      "                    (0): Linear(in_features=256, out_features=8, bias=True)\n",
      "                    (1): ReLU(inplace)\n",
      "                    (2): Linear(in_features=8, out_features=128, bias=True)\n",
      "                    (3): Sigmoid()\n",
      "                  )\n",
      "                )\n",
      "                (mixed_attention): GlobalAttentionModule(\n",
      "                  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "                  (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "                  (fc): Sequential(\n",
      "                    (0): Linear(in_features=256, out_features=8, bias=True)\n",
      "                    (1): ReLU(inplace)\n",
      "                    (2): Linear(in_features=8, out_features=128, bias=True)\n",
      "                    (3): Sigmoid()\n",
      "                  )\n",
      "                )\n",
      "                (spliced_attention): GlobalAttentionModule(\n",
      "                  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "                  (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "                  (fc): Sequential(\n",
      "                    (0): Linear(in_features=256, out_features=8, bias=True)\n",
      "                    (1): ReLU(inplace)\n",
      "                    (2): Linear(in_features=8, out_features=128, bias=True)\n",
      "                    (3): Sigmoid()\n",
      "                  )\n",
      "                )\n",
      "                (gaussianMask): GaussianSmoothing()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (attention): RegionalAttentionConnectGaussianMask(\n",
      "            (connection): RegionalSkipConnect(\n",
      "              (rconv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (rbn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (rconv2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (rbn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (background_attention): GlobalAttentionModule(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "                (1): ReLU(inplace)\n",
      "                (2): Linear(in_features=4, out_features=64, bias=True)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (mixed_attention): GlobalAttentionModule(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "                (1): ReLU(inplace)\n",
      "                (2): Linear(in_features=4, out_features=64, bias=True)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (spliced_attention): GlobalAttentionModule(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "              (fc): Sequential(\n",
      "                (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "                (1): ReLU(inplace)\n",
      "                (2): Linear(in_features=4, out_features=64, bias=True)\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (gaussianMask): GaussianSmoothing()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
